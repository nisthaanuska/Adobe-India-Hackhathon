# Persona-Driven Document Intelligence (Round 1B)

> **Rethink Reading. Rediscover Knowledge.**  
Transform static PDFs into an intelligent, interactive experience. This solution extracts, ranks, and surfaces the most relevant sections from a collection of documentsâ€”tailored to a specific persona and their job-to-be-done.

---

## ğŸš€ Features

- **Persona-Aware Extraction**: Surfaces what matters most for each user and task.  
- **Multi-Document Support**: Handles 3â€“10 PDFs per test case, across any domain.  
- **Contextual Ranking**: Prioritizes sections using persona/job-driven relevance.  
- **Modular & Extensible**: Easy to adapt for new domains, personas, or advanced NLP.  
- **Offline & Secure**: Runs fully offline, with no network dependencies.

---

## ğŸ“¥ Input

Each test case folder (e.g., `TestCase1_AcademicResearch/`) must contain:

- `input.json` â€” Specifies:
  - `persona`: Role and focus areas (e.g., "PhD Researcher in Computational Biology")
  - `job_to_be_done`: The concrete task (e.g., "Prepare a literature review...")
  - `documents`: List of PDF file paths (relative to the test case folder)
- `pdfs/` â€” Subfolder containing the referenced PDFs

**Example `input.json`:**

```json
{
  "persona": {
    "role": "PhD Researcher in Computational Biology",
    "focus_areas": ["methodologies", "datasets", "performance benchmarks"]
  },
  "job_to_be_done": "Prepare a comprehensive literature review focusing on methodologies, datasets, and performance benchmarks.",
  "documents": [
    "pdfs/Research1.pdf",
    "pdfs/Research2.pdf"
  ]
}
```

---

## ğŸ“¤ Output

For each test case, an `output.json` is generated in the same folder, containing:

- **Metadata**: Input docs, persona, job, timestamp  
- **Extracted Sections**: Ranked by relevance, with section title, page, and importance rank

---

## ğŸ› ï¸ Usage

1. **Organize Test Cases**  
   Place each test case folder (with `input.json` and `pdfs/`) inside `Round1B/`.

2. **Build Docker Image**
   ```sh
   docker build --platform linux/amd64 -t round1b_solution:latest .
   ```

3. **Run the Solution**
   ```sh
   docker run --rm -v "$(pwd):/app" --network none round1b_solution:latest
   ```

   All test cases will be processed; each will get its own `output.json`.

---

## ğŸ§© Folder Structure

```
Round1B/
â”œâ”€â”€ main.py                         # Entry point
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ extractor.py                # PDF parsing and section extraction
â”‚   â””â”€â”€ relevance.py                # Relevance scoring logic
â”œâ”€â”€ TestCase1_AcademicResearch/
â”‚   â”œâ”€â”€ input.json
â”‚   â””â”€â”€ pdfs/
â”œâ”€â”€ ... (other test cases)
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ approach_explanation.md
```

---

## ğŸ” Extensibility

- **Semantic Ranking**: Integrate spaCy or transformer models for deeper relevance  
- **Sub-section Analysis**: Expand to extract and rank granular sub-sections  
- **Multilingual Support**: Plug in language models for global document sets

---

## ğŸ“ Credits

- Developed for the Adobe India Hackathon 2025 â€” "Connecting the Dots" Challenge  
- Built with Python, PyMuPDF, and a passion for smarter reading

---

## ğŸ“š See Also

- [Approach Explanation](./approach_explanation.md) â€” In-depth methodology and design rationale
